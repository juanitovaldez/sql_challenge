{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL-Challenge\n",
    "## Setting up SQL-Alchemy and Postgresql:\n",
    "In the relentless drive to code my way around repetative importing, I have abandoned trying to get my bash script working and am going straight for the sonic screwdriver that is python.\n",
    "\n",
    "The tables have been created, now i need to bulk load the data into the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:00:19.950427Z",
     "start_time": "2019-11-16T19:00:19.320114Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import postgres_config as pcfg\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "print(pcfg.pg_engine_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing tables\n",
    "The data currently exists as multiple .csv files in a folder somewhere. The next task is to craft a loop with a copy statement that iterates through the csv files. Luckily, the table names are the same as the basename of the files. Don't manualy import your files.\n",
    "1. declare folder path\n",
    "2. get list of *.csv\n",
    "3. loop copy\n",
    "4. Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:00:19.958406Z",
     "start_time": "2019-11-16T19:00:19.951425Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1-2 Get list of files to import and table names\n",
    "file_path = 'data/'\n",
    "tables = [str.split(file,'.')[0] for file in os.listdir(path='data/') if fnmatch.fnmatch(file, '*.csv')]\n",
    "# Because I had the relationship already defined in the tables, there are foreign key\n",
    "# dependencies to take into account. I had to re order the lsit accordingly so\n",
    "# the immaculate tables get loaded first.\n",
    "# Perhaps develope a way to create an ordered permutation list that ranks the\n",
    "# name of the tables by number of fk dependencies\n",
    "permute = [3, 0, 1, 2, 4, 5]\n",
    "tables =  [tables[i] for i in permute]\n",
    "print(tables)\n",
    "print(pcfg.postgres_password)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:01:28.672572Z",
     "start_time": "2019-11-16T19:01:11.145141Z"
    }
   },
   "outputs": [],
   "source": [
    "#3 loop through list to copy into the tables:\n",
    "# I googled the copy_expert thing for psycopg2 which lets you write function\n",
    "# that sends the postgres server a psql copy command. copy is supposed to be very fast.\n",
    "# I have already defined the schema using an erd tool. this will hopefully\n",
    "# populate the tables from the csvs. \n",
    "#conn = psycopg2.connect(f'dbname={pcfg.postgres_dbname}, user={pcfg.postgres_username}, password={pcfg.postgres_password}, host={pcfg.postgres_address}, port={pcfg.postgres_port}')\n",
    "\n",
    "#This is really handy. I should turn this into a generic function for use elsewhere.\n",
    "conn = psycopg2.connect(pcfg.pg_engine_params)\n",
    "for table_name in tables:\n",
    "    # we are reading the csv from STDIN. the open command below reads the csv \n",
    "    # into stdin\n",
    "    print(table_name)\n",
    "    sql = f\"COPY {table_name} FROM STDIN WITH CSV HEADER DELIMITER AS ','\"\n",
    "    file = open(f'{file_path}/{table_name}.csv', \"r\")\n",
    "    table = table_name\n",
    "    with conn.cursor() as cur:\n",
    "        # truncate is a potentialy dangerous function, but we might\n",
    "        # run this cell several times. This wipes the tables clean so we \n",
    "        # don't append repeated data\n",
    "        cur.execute(f'truncate {table_name} cascade;')\n",
    "        cur.copy_expert(sql=f'{sql}', file=file)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the database connection\n",
    "Now it's time to create a bar chart from the view of avg salary by tittle. Way easier than messing with dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:01:35.714417Z",
     "start_time": "2019-11-16T19:01:35.455889Z"
    }
   },
   "outputs": [],
   "source": [
    "cnx = create_engine(pcfg.pg_engine_params)\n",
    "view_name = 'public.average_salary'\n",
    "avg_salary_df = pd.read_sql(f'SELECT * FROM {view_name}', cnx)\n",
    "avg_salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:01:53.310790Z",
     "start_time": "2019-11-16T19:01:53.186126Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_salary_df.plot.bar(x='title', y='salary_average')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
